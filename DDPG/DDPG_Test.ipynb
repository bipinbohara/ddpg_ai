{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/anaconda3/lib/python3.12/site-packages/tensorflow/python/compat/v2_compat.py:98: disable_resource_variables (from tensorflow.python.ops.resource_variables_toggle) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "INFO:tensorflow:Restoring parameters from folder_for_nn_noise/EH_save_net_snr=-100epoch=1999_P2P.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1732833756.139955  243944 mlir_graph_optimization_pass.cc:401] MLIR V1 optimization pass is not enabled\n",
      "/opt/anaconda3/lib/python3.12/site-packages/tensorflow/python/client/session.py:1483: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Argument `fetch` = Actor/eval_net/a/a/kernel:0 cannot be interpreted as a Tensor. (\"The name 'Actor/eval_net/a/a/kernel:0' refers to a Tensor which does not exist. The operation, 'Actor/eval_net/a/a/kernel', does not exist in the graph.\")",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/tensorflow/python/framework/ops.py:2944\u001b[0m, in \u001b[0;36mGraph._as_graph_element_locked\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   2943\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2944\u001b[0m   op \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_operation_by_name(op_name)\n\u001b[1;32m   2945\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[0;31mKeyError\u001b[0m: ''",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/tensorflow/python/client/session.py:313\u001b[0m, in \u001b[0;36m_ElementFetchMapper.__init__\u001b[0;34m(self, fetches, contraction_fn)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 313\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unique_fetches\u001b[38;5;241m.\u001b[39mappend(ops\u001b[38;5;241m.\u001b[39mget_default_graph()\u001b[38;5;241m.\u001b[39mas_graph_element(\n\u001b[1;32m    314\u001b[0m       fetch, allow_tensor\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, allow_operation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m))\n\u001b[1;32m    315\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/tensorflow/python/framework/ops.py:2904\u001b[0m, in \u001b[0;36mGraph.as_graph_element\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   2903\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m-> 2904\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_as_graph_element_locked(obj, allow_tensor, allow_operation)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/tensorflow/python/framework/ops.py:2946\u001b[0m, in \u001b[0;36mGraph._as_graph_element_locked\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   2945\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m-> 2946\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\n\u001b[1;32m   2947\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe name \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m refers to a Tensor which does not \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2948\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexist. The operation, \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m, does not exist in the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2949\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgraph.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mrepr\u001b[39m(name), \u001b[38;5;28mrepr\u001b[39m(op_name))\n\u001b[1;32m   2950\u001b[0m   ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n\u001b[1;32m   2952\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mKeyError\u001b[0m: \"The name 'Actor/eval_net/a/a/kernel:0' refers to a Tensor which does not exist. The operation, 'Actor/eval_net/a/a/kernel', does not exist in the graph.\"",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 55\u001b[0m\n\u001b[1;32m     53\u001b[0m a3 \u001b[38;5;241m=\u001b[39m sess\u001b[38;5;241m.\u001b[39mrun(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mActor/eval_net/l3/kernel:0\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     54\u001b[0m b3 \u001b[38;5;241m=\u001b[39m sess\u001b[38;5;241m.\u001b[39mrun(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mActor/eval_net/l3/bias:0\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 55\u001b[0m aa \u001b[38;5;241m=\u001b[39m sess\u001b[38;5;241m.\u001b[39mrun(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mActor/eval_net/a/a/kernel:0\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     56\u001b[0m ba \u001b[38;5;241m=\u001b[39m sess\u001b[38;5;241m.\u001b[39mrun(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mActor/eval_net/a/a/bias:0\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(MAX_EPISODES):\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/tensorflow/python/client/session.py:977\u001b[0m, in \u001b[0;36mBaseSession.run\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    974\u001b[0m run_metadata_ptr \u001b[38;5;241m=\u001b[39m tf_session\u001b[38;5;241m.\u001b[39mTF_NewBuffer() \u001b[38;5;28;01mif\u001b[39;00m run_metadata \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    976\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 977\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run(\u001b[38;5;28;01mNone\u001b[39;00m, fetches, feed_dict, options_ptr,\n\u001b[1;32m    978\u001b[0m                      run_metadata_ptr)\n\u001b[1;32m    979\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m run_metadata:\n\u001b[1;32m    980\u001b[0m     proto_data \u001b[38;5;241m=\u001b[39m tf_session\u001b[38;5;241m.\u001b[39mTF_GetBuffer(run_metadata_ptr)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/tensorflow/python/client/session.py:1205\u001b[0m, in \u001b[0;36mBaseSession._run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1202\u001b[0m       feed_map[compat\u001b[38;5;241m.\u001b[39mas_bytes(subfeed_t\u001b[38;5;241m.\u001b[39mname)] \u001b[38;5;241m=\u001b[39m (subfeed_t, subfeed_val)\n\u001b[1;32m   1204\u001b[0m \u001b[38;5;66;03m# Create a fetch handler to take care of the structure of fetches.\u001b[39;00m\n\u001b[0;32m-> 1205\u001b[0m fetch_handler \u001b[38;5;241m=\u001b[39m _FetchHandler(\n\u001b[1;32m   1206\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graph, fetches, feed_dict_tensor, feed_handles\u001b[38;5;241m=\u001b[39mfeed_handles)\n\u001b[1;32m   1208\u001b[0m \u001b[38;5;66;03m# Run request and get response.\u001b[39;00m\n\u001b[1;32m   1209\u001b[0m \u001b[38;5;66;03m# We need to keep the returned movers alive for the following _do_run().\u001b[39;00m\n\u001b[1;32m   1210\u001b[0m \u001b[38;5;66;03m# These movers are no longer needed when _do_run() completes, and\u001b[39;00m\n\u001b[1;32m   1211\u001b[0m \u001b[38;5;66;03m# are deleted when `movers` goes out of scope when this _run() ends.\u001b[39;00m\n\u001b[1;32m   1212\u001b[0m \u001b[38;5;66;03m# TODO(yuanbyu, keveman): Revisit whether we should just treat feeding\u001b[39;00m\n\u001b[1;32m   1213\u001b[0m \u001b[38;5;66;03m# of a handle from a different device as an error.\u001b[39;00m\n\u001b[1;32m   1214\u001b[0m _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_with_movers(feed_dict_tensor, feed_map)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/tensorflow/python/client/session.py:494\u001b[0m, in \u001b[0;36m_FetchHandler.__init__\u001b[0;34m(self, graph, fetches, feeds, feed_handles)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Creates a fetch handler.\u001b[39;00m\n\u001b[1;32m    483\u001b[0m \n\u001b[1;32m    484\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    491\u001b[0m \u001b[38;5;124;03m    direct feeds.\u001b[39;00m\n\u001b[1;32m    492\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    493\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m graph\u001b[38;5;241m.\u001b[39mas_default():\n\u001b[0;32m--> 494\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fetch_mapper \u001b[38;5;241m=\u001b[39m _FetchMapper\u001b[38;5;241m.\u001b[39mfor_fetch(fetches)\n\u001b[1;32m    495\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fetches \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    496\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_targets \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/tensorflow/python/client/session.py:285\u001b[0m, in \u001b[0;36m_FetchMapper.for_fetch\u001b[0;34m(fetch)\u001b[0m\n\u001b[1;32m    283\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fetch, tensor_type):\n\u001b[1;32m    284\u001b[0m       fetches, contraction_fn \u001b[38;5;241m=\u001b[39m fetch_fn(fetch)\n\u001b[0;32m--> 285\u001b[0m       \u001b[38;5;28;01mreturn\u001b[39;00m _ElementFetchMapper(fetches, contraction_fn)\n\u001b[1;32m    286\u001b[0m \u001b[38;5;66;03m# Did not find anything.\u001b[39;00m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mArgument `fetch` = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfetch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m has invalid type \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    288\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(fetch)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/tensorflow/python/client/session.py:323\u001b[0m, in \u001b[0;36m_ElementFetchMapper.__init__\u001b[0;34m(self, fetches, contraction_fn)\u001b[0m\n\u001b[1;32m    320\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mArgument `fetch` = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfetch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m cannot be interpreted as \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    321\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma Tensor. (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    322\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 323\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mArgument `fetch` = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfetch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m cannot be interpreted as \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    324\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma Tensor. (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_contraction_fn \u001b[38;5;241m=\u001b[39m contraction_fn\n",
      "\u001b[0;31mValueError\u001b[0m: Argument `fetch` = Actor/eval_net/a/a/kernel:0 cannot be interpreted as a Tensor. (\"The name 'Actor/eval_net/a/a/kernel:0' refers to a Tensor which does not exist. The operation, 'Actor/eval_net/a/a/kernel', does not exist in the graph.\")"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Deep Deterministic Policy Gradient (DDPG), Reinforcement Learning.\n",
    "P2P, net bit rate, energy harvesting example for validation.\n",
    "Using:\n",
    "tensorflow 1.0\n",
    "\"\"\"\n",
    "#import tensorflow as tf\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "import numpy as np\n",
    "import gym\n",
    "import time\n",
    "import EH_P2P\n",
    "import math\n",
    "\n",
    "MAX_EPISODES = 1\n",
    "MAX_EP_STEPS = 100000\n",
    "\n",
    "RENDER = False\n",
    "OUTPUT_GRAPH = True\n",
    "\n",
    "env=EH_P2P.EH_P2P()\n",
    "env.Chanpower()\n",
    "env.Solarread()\n",
    "B=np.zeros((100,4))    \n",
    "\n",
    "def dense(x,a,b):\n",
    "    results=(x.dot(a)+b)\n",
    "    return results\n",
    "\n",
    "def choose_action(s):\n",
    "    a=dense(s,a1,b1)\n",
    "    a=dense(a,a3,b3)\n",
    "    a=dense(a,aa,ba)\n",
    "    a=1/(1+np.exp(-a))\n",
    "    a = np.clip(a, 0, 1)\n",
    "    return a\n",
    "\n",
    "for snr in range (-10,-8,2):\n",
    "\n",
    "    for epoch in range (0,1750,30):\n",
    "\n",
    "        modulation=0\n",
    "\n",
    "        tf.reset_default_graph()\n",
    "        graph = tf.get_default_graph()\n",
    "        \n",
    "        saver = tf.train.import_meta_graph(\"folder_for_nn_noise\"+\"/EH_save_net_snr=\"+str(snr)+str(modulation)+\"epoch=\"+str(epoch)+\"_P2P.ckpt.meta\")\n",
    "        with tf.Session() as sess:\n",
    "            saver.restore(sess,\"folder_for_nn_noise\"+\"/EH_save_net_snr=\"+str(snr)+str(modulation)+\"epoch=\"+str(epoch)+\"_P2P.ckpt\")\n",
    "\n",
    "            a1 = sess.run('Actor/eval_net/l1/kernel:0')\n",
    "            b1 = sess.run('Actor/eval_net/l1/bias:0')\n",
    "            a3 = sess.run('Actor/eval_net/l3/kernel:0')\n",
    "            b3 = sess.run('Actor/eval_net/l3/bias:0')\n",
    "            aa = sess.run('Actor/eval_net/a/a/kernel:0')\n",
    "            ba = sess.run('Actor/eval_net/a/a/bias:0')\n",
    "    \n",
    "\n",
    "    \n",
    "            for i in range(MAX_EPISODES):\n",
    "\n",
    "                s = env.reset_P2P(snr=snr)\n",
    "                s=np.reshape(s,(1,-1))\n",
    "                ep_reward = 0\n",
    "                for j in range(MAX_EP_STEPS):\n",
    "                    s=np.array(s,dtype=float)\n",
    "                    a=choose_action(s)\n",
    "                    s_, r, info = env.step_P2P([a,modulation])\n",
    "                    s = s_\n",
    "                    ep_reward += r\n",
    "                    if (j+1)%10000==0:\n",
    "                        print(\"net bit rate=\",ep_reward/j,\"snr=\",snr,\"modulation=\",modulation, \"loop =\",i,\"action=\",a,\"noise=\",env.noise)\n",
    "          \n",
    "                index=(snr+10)/2\n",
    "                B[int(index),int(modulation)]=ep_reward/j\n",
    "                print(B[int(index),int(modulation)])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/anaconda3/lib/python3.12/site-packages/tensorflow/python/compat/v2_compat.py:98: disable_resource_variables (from tensorflow.python.ops.resource_variables_toggle) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "INFO:tensorflow:Restoring parameters from folder_for_nn_noise/EH_save_net_snr=-100epoch=1999_P2P.ckpt\n",
      "Shape a1: (168,), Shape b1: (168,)\n",
      "Shape a3: (168,), Shape b3: (168,)\n",
      "Shape aa: (168,), Shape ba: (168,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1732848049.265537  361107 mlir_graph_optimization_pass.cc:401] MLIR V1 optimization pass is not enabled\n",
      "/opt/anaconda3/lib/python3.12/site-packages/tensorflow/python/client/session.py:1483: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "cannot access local variable 'a1' where it is not associated with a value",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 105\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(MAX_EP_STEPS):\n\u001b[1;32m    104\u001b[0m     s\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39marray(s,dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mfloat\u001b[39m)\n\u001b[0;32m--> 105\u001b[0m     a\u001b[38;5;241m=\u001b[39mchoose_action(s)\n\u001b[1;32m    106\u001b[0m     s_, r, info \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mstep_P2P([a,modulation])\n\u001b[1;32m    107\u001b[0m     s \u001b[38;5;241m=\u001b[39m s_\n",
      "Cell \u001b[0;32mIn[1], line 34\u001b[0m, in \u001b[0;36mchoose_action\u001b[0;34m(s)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mchoose_action\u001b[39m(s):\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;66;03m# Fix input shape mismatch if necessary\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m s\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m!=\u001b[39m a1\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n\u001b[1;32m     35\u001b[0m         \u001b[38;5;66;03m#print(f\"Padding input s from shape {s.shape} to match a1 shape {a1.shape}\")\u001b[39;00m\n\u001b[1;32m     36\u001b[0m         s \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mpad(s, ((\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m), (\u001b[38;5;241m0\u001b[39m, a1\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m-\u001b[39m s\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconstant\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m a1\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m!=\u001b[39m b1\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n\u001b[1;32m     39\u001b[0m         \u001b[38;5;66;03m#print(f\"Padding input a1 from shape {a1.shape} to match b1 shape {b1.shape}\")\u001b[39;00m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: cannot access local variable 'a1' where it is not associated with a value"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Deep Deterministic Policy Gradient (DDPG), Reinforcement Learning.\n",
    "P2P, net bit rate, energy harvesting example for validation.\n",
    "Using:\n",
    "tensorflow 1.0\n",
    "\"\"\"\n",
    "#import tensorflow as tf\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "import numpy as np\n",
    "import gym\n",
    "import time\n",
    "import EH_P2P\n",
    "import math\n",
    "\n",
    "MAX_EPISODES = 1\n",
    "MAX_EP_STEPS = 100000\n",
    "\n",
    "RENDER = False\n",
    "OUTPUT_GRAPH = True\n",
    "\n",
    "env=EH_P2P.EH_P2P()\n",
    "env.Chanpower()\n",
    "env.Solarread()\n",
    "B=np.zeros((100,4))    \n",
    "\n",
    "def dense(x,a,b):\n",
    "    results=(x.dot(a)+b)\n",
    "    return results\n",
    "\n",
    "def choose_action(s):\n",
    "    # Fix input shape mismatch if necessary\n",
    "    if s.shape[1] != a1.shape[0]:\n",
    "        #print(f\"Padding input s from shape {s.shape} to match a1 shape {a1.shape}\")\n",
    "        s = np.pad(s, ((0, 0), (0, a1.shape[0] - s.shape[1])), 'constant')\n",
    "    \n",
    "    # if a1.shape[1] != b1.shape[0]:\n",
    "    #     #print(f\"Padding input a1 from shape {a1.shape} to match b1 shape {b1.shape}\")\n",
    "    #     a1 = np.pad(s, ((0, 0), (0, b1.shape[0] - a1.shape[1])), 'constant')\n",
    "    \n",
    "    # if a1.shape[1] != b1.shape[0]:\n",
    "    #     #print(f\"Padding input a1 from shape {a1.shape} to match b1 shape {b1.shape}\")\n",
    "    #     a1 = np.pad(s, ((0, 0), (0, b1.shape[0] - a1.shape[1])), 'constant')\n",
    "\n",
    "    print(\"Reshaped s: \", s.shape)\n",
    "    print(\"Reshaped a1: \", a1.shape)\n",
    "    \n",
    "    a=dense(s,a1,b1)\n",
    "    a=dense(a,a3,b3)\n",
    "    a=dense(a,aa,ba)\n",
    "\n",
    "    # a=dense(s, a1_reshaped, b1_reshaped)\n",
    "    # a=dense(s, a3_reshaped, b3_reshaped)\n",
    "    # a=dense(s, aa_reshaped, ba_reshaped)\n",
    "\n",
    "    a=1/(1+np.exp(-a))\n",
    "    a = np.clip(a, 0, 1)\n",
    "    return a\n",
    "\n",
    "\n",
    "snr=-10\n",
    "epoch=1999\n",
    "modulation=0\n",
    "\n",
    "tf.reset_default_graph()\n",
    "graph = tf.get_default_graph()\n",
    "\n",
    "saver = tf.train.import_meta_graph(\"folder_for_nn_noise\"+\"/EH_save_net_snr=\"+str(snr)+str(modulation)+\"epoch=\"+str(epoch)+\"_P2P.ckpt.meta\")\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess,\"folder_for_nn_noise\"+\"/EH_save_net_snr=\"+str(snr)+str(modulation)+\"epoch=\"+str(epoch)+\"_P2P.ckpt\")\n",
    "\n",
    "    a1 = sess.run('Actor/eval_net/l1/kernel:0')\n",
    "    b1 = sess.run('Actor/eval_net/l1/bias:0')\n",
    "    a3 = sess.run('Actor/eval_net/l3/kernel:0')\n",
    "    b3 = sess.run('Actor/eval_net/l3/bias:0')\n",
    "    aa = sess.run('Actor/eval_net/a/kernel:0')\n",
    "    ba = sess.run('Actor/eval_net/a/bias:0')\n",
    "\n",
    "    print(f\"Shape a1: {a1.shape}, Shape b1: {b1.shape}\")\n",
    "    print(f\"Shape a3: {a3.shape}, Shape b3: {b3.shape}\")\n",
    "    print(f\"Shape aa: {aa.shape}, Shape ba: {ba.shape}\")\n",
    "    \n",
    "    # input_dim = 168  # Adjust this to match your model's expected input size\n",
    "    # output_dim = 168  # Adjust this to match your model's hidden layer size\n",
    "\n",
    "    # a1 = np.reshape(a1, (input_dim, output_dim))\n",
    "    # b1 = np.reshape(b1, (output_dim,))\n",
    "    # a3 = np.reshape(a3, (output_dim, output_dim))\n",
    "    # b3 = np.reshape(b3, (output_dim,))\n",
    "    # aa = np.reshape(aa, (output_dim, output_dim))\n",
    "    # ba = np.reshape(ba, (output_dim,))\n",
    "\n",
    "    # print(f\"Reshaped a1: {a1.shape}, Reshaped b1: {b1.shape}\")\n",
    "    # print(f\"Reshaped a3: {a3.shape}, Reshaped b3: {b3.shape}\")\n",
    "    # print(f\"Reshaped aa: {aa.shape}, Reshaped ba: {ba.shape}\")\n",
    "\n",
    "    for i in range(MAX_EPISODES):\n",
    "\n",
    "        s = env.reset_P2P(snr=snr)\n",
    "        s=np.reshape(s,(1,-1))\n",
    "        ep_reward = 0\n",
    "        for j in range(MAX_EP_STEPS):\n",
    "            s=np.array(s,dtype=float)\n",
    "            a=choose_action(s)\n",
    "            s_, r, info = env.step_P2P([a,modulation])\n",
    "            s = s_\n",
    "            ep_reward += r\n",
    "            if (j+1)%10000==0:\n",
    "                print(\"net bit rate=\",ep_reward/j,\"snr=\",snr,\"modulation=\",modulation, \"loop =\",i,\"action=\",a,\"noise=\",env.noise)\n",
    "    \n",
    "        index=(snr+10)/2\n",
    "        B[int(index),int(modulation)]=ep_reward/j\n",
    "        print(B[int(index),int(modulation)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"DDPG_P2P_noise2\"+str(snr)+\".csv\", B, delimiter = ',')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
